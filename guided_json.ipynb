{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "import json\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.studio.nebius.ai/v1/\",\n",
    "    api_key=os.getenv('NB_STUDIO_API_KEY')\n",
    ")\n",
    "\n",
    "model=\"meta-llama/Meta-Llama-3.1-8B-Instruct-fast\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chat-4d4d16562cf44fe5b44b07c2235e7a1c\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"{\\\"first_name\\\": \\\"Mikhail\\\", \\\"surname\\\": \\\"Kashirskii\\\", \\\"role\\\": \\\"Software Developer\\\"}\",\n",
      "        \"role\": \"assistant\",\n",
      "        \"function_call\": null,\n",
      "        \"tool_calls\": []\n",
      "      },\n",
      "      \"stop_reason\": null\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1725969933,\n",
      "  \"model\": \"meta-llama/Meta-Llama-3.1-8B-Instruct-fast\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"service_tier\": null,\n",
      "  \"system_fingerprint\": null,\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 26,\n",
      "    \"prompt_tokens\": 187,\n",
      "    \"total_tokens\": 213\n",
      "  },\n",
      "  \"prompt_logprobs\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class PersonOutput(BaseModel):\n",
    "    first_name: str\n",
    "    surname: str\n",
    "    role: str = Field(description = 'Role of the person in the company.')\n",
    "\n",
    "schema = PersonOutput.schema()\n",
    "\n",
    "text = \"\"\"\n",
    "The task of json generation was assigned Mikhail Kashirskii, a software developer at Nebius. \\\n",
    "His role in this task is to implement the support of json outputs of the LLM.\n",
    "\"\"\".strip()\n",
    "\n",
    "system_prompt = f\"\"\"\n",
    "Act as an experienced data extractor. \\\n",
    "Your goal is to extract the required information (is given below) from the text. \\\n",
    "Output the extracted information in the json format, following the required schema.\n",
    "Required information schema:\n",
    "```\n",
    "{schema}\n",
    "```\n",
    "\"\"\".strip()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": text\n",
    "        }\n",
    "    ],\n",
    "    extra_body={\n",
    "        \"guided_json\": schema,\n",
    "    },\n",
    "\n",
    "    temperature=0.6,\n",
    "    max_tokens=51,\n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "print(completion.to_json())\n",
    "person = PersonOutput(**json.loads(completion.choices[0].message.content))\n",
    "assert person.first_name == 'Mikhail'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chat-0ca99f6a8fc9447690ff0a5e4b866954\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"finish_reason\": \"stop\",\n",
      "      \"index\": 0,\n",
      "      \"logprobs\": null,\n",
      "      \"message\": {\n",
      "        \"content\": \"{ \\n   \\t\\\"first_name\\\" \\t: \\t\\\"Mikhail\\\" \\t, \\n\\t\\\"surname\\\" \\t: \\t\\\"Kashirskii\\\" \\t, \\n\\t\\\"role\\\" \\t: \\t\\\"Software developer at Nebius\\\" \\n}\",\n",
      "        \"role\": \"assistant\",\n",
      "        \"function_call\": null,\n",
      "        \"tool_calls\": []\n",
      "      },\n",
      "      \"stop_reason\": null\n",
      "    }\n",
      "  ],\n",
      "  \"created\": 1725969934,\n",
      "  \"model\": \"meta-llama/Meta-Llama-3.1-8B-Instruct-fast\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"service_tier\": null,\n",
      "  \"system_fingerprint\": null,\n",
      "  \"usage\": {\n",
      "    \"completion_tokens\": 59,\n",
      "    \"prompt_tokens\": 187,\n",
      "    \"total_tokens\": 246\n",
      "  },\n",
      "  \"prompt_logprobs\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": text\n",
    "        }\n",
    "    ],\n",
    "    response_format={ \"type\": \"json_object\" },\n",
    "\n",
    "    temperature=0.6,\n",
    "    max_tokens=151,\n",
    "    top_p=0.9\n",
    ")\n",
    "\n",
    "print(completion.to_json())\n",
    "person = PersonOutput(**json.loads(completion.choices[0].message.content))\n",
    "assert person.first_name == 'Mikhail'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "system_prompt = f\"\"\"\n",
    "Based on the person's description, classify whether the person has relation to AI or not. \\\n",
    "Output only \"True\" if the person has relation to IT or \"False\", otherwise.\n",
    "\"\"\".strip()\n",
    "\n",
    "text = \"\"\"\n",
    "Mikhail Kashirskii, a software developer at Nebius, was assigned the task of json generation. \\\n",
    "His role in this task is to implement the support of json outputs of the LLM.\n",
    "\"\"\".strip()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": text\n",
    "        }\n",
    "    ],\n",
    "    temperature=0.,\n",
    "    extra_body={\n",
    "        \"guided_choice\": [\"True\", \"False\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "assert completion.choices[0].message.content == 'True'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
