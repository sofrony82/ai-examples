{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded successfully with ID: file-878b7628-6ec5-4915-9ce9-240cda24bd81\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'meta-llama/Meta-Llama-3.1-8B-Instruct-LoRa:Sofrony-Test-hUUO',\n",
       " 'base_model': 'meta-llama/Meta-Llama-3.1-8B-Instruct',\n",
       " 'source': 'file-878b7628-6ec5-4915-9ce9-240cda24bd81',\n",
       " 'description': 'description',\n",
       " 'created_at': 1744635333,\n",
       " 'status': 'validating'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests \n",
    "import os  \n",
    "from openai import OpenAI \n",
    "\n",
    "# Set up API credentials and endpoints\n",
    "openai_api_key=os.getenv(\"OPENAI_API_KEY\")  # Get OpenAI API key from environment variables\n",
    "api_url=\"https://api.studio.nebius.ai\"  # Base URL for the Nebius AI Studio API\n",
    "base_url = api_url+\"/v1\"  # v1 API endpoint\n",
    "\n",
    "# Initialize the OpenAI client with custom base URL and API key\n",
    "client = OpenAI(\n",
    "    base_url=base_url,\n",
    "    api_key=os.getenv('NB_STUDIO_API_KEY', 'ANY'),  # Use Nebius Studio API key or fallback to 'ANY'\n",
    ")\n",
    "\n",
    "def upload_file(file_name):\n",
    "    # Upload the file to the API server\n",
    "    with open(file_name, \"rb\") as file_data:\n",
    "        files = {\"file\": (os.path.basename(file_name), file_data)}\n",
    "        upload_response = requests.post(\n",
    "            f\"{api_url}/v0/models/upload\",\n",
    "            files=files,\n",
    "            headers={\"Authorization\": f\"Bearer {openai_api_key}\"}\n",
    "        )\n",
    "    \n",
    "    # Check if the upload was successful\n",
    "    if upload_response.status_code != 200:\n",
    "        print(f\"Error uploading file: {upload_response.text}\")\n",
    "        return upload_response.json()\n",
    "    \n",
    "    # Get and return the uploaded file ID\n",
    "    file_info = upload_response.json()\n",
    "    file_id = file_info[\"id\"]\n",
    "    print(f\"File uploaded successfully with ID: {file_id}\")\n",
    "    return file_id\n",
    "\n",
    "def create_lora_from_file(name, file_id, base_model):    \n",
    "    # Create the LoRA model using the uploaded file\n",
    "    lora_creation_request = {\n",
    "        \"source\": file_id,  # ID of the uploaded training data\n",
    "        \"base_model\": base_model,  # Base model to adapt\n",
    "        \"name\": name,  # Name for the new model\n",
    "        \"description\": \"description\"  # Description of the model\n",
    "    }\n",
    "    \n",
    "    # Send request to create the model\n",
    "    model_response = requests.post(\n",
    "        f\"{api_url}/v0/models\", \n",
    "        json=lora_creation_request,\n",
    "        headers={\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {openai_api_key}\"}\n",
    "    ) \n",
    "    \n",
    "    return(model_response.json())\n",
    "\n",
    "def delete_lora(model):\n",
    "    return requests.delete(f\"{api_url}/v0/models/{model}\",                         \n",
    "      headers={\"Content-Type\": \"application/json\",\"Authorization\": f\"Bearer {os.getenv('NB_STUDIO_API_KEY')}\"})  \n",
    "\n",
    "\n",
    "def list_loras():\n",
    "    return requests.get(f\"{api_url}/v0/models\",                         \n",
    "      headers={\"Content-Type\": \"application/json\",\"Authorization\": f\"Bearer {os.getenv('NB_STUDIO_API_KEY')}\"})  \n",
    "\n",
    "def get_completion(model):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\":\"user\",\"content\":'hi'}],  # Simple test prompt\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "\n",
    "# Define path to the lora adapter archive file with adapter_config.json and adapter_model.safetensors\n",
    "zip_file_name=\"/Users/sofrony/tmp/LORA.zip\"\n",
    "    # Upload the file and get the file ID\n",
    "file_id = upload_file(zip_file_name)\n",
    "\n",
    "# Create a new LoRA model using the file_id\n",
    "create_lora_from_file(\"Sofrony-Test\", file_id, \"meta-llama/Meta-Llama-3.1-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'text2text',\n",
       " 'name': 'meta-llama/Meta-Llama-3.1-8B-Instruct-LoRa:Sofrony-Test-hUUO',\n",
       " 'status': 'active',\n",
       " 'status_reason': None,\n",
       " 'checkpoint_id': None,\n",
       " 'job_id': None,\n",
       " 'file_id': 'file-878b7628-6ec5-4915-9ce9-240cda24bd81',\n",
       " 'url': None,\n",
       " 'created_at': 1744635333,\n",
       " 'description': 'description',\n",
       " 'vendor': 'meta',\n",
       " 'tags': ['128K context', 'small', 'JSON mode', 'lora'],\n",
       " 'use_cases': ['lora'],\n",
       " 'quality': 73,\n",
       " 'context_window_k': 128,\n",
       " 'size_b': 8.03}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_lora = list_loras().json()[-1]  # list loras and get the last one\n",
    "last_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How can I assist you today?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(last_lora[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'meta-llama/Meta-Llama-3.1-8B-Instruct-LoRa:Sofrony-Test-hUUO',\n",
       " 'base_model': 'meta-llama/Meta-Llama-3.1-8B-Instruct',\n",
       " 'source': 'file-878b7628-6ec5-4915-9ce9-240cda24bd81',\n",
       " 'description': 'description',\n",
       " 'created_at': 1744635333,\n",
       " 'status': 'deleted'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delete_lora(last_lora[\"name\"]).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'meta-llama/Meta-Llama-3.1-8B-Instruct-LoRa:sofrony-URL-cdRh',\n",
       " 'base_model': 'meta-llama/Meta-Llama-3.1-8B-Instruct',\n",
       " 'source': 'sofrony/Llama-3.1-8B-Instruct-sofrony',\n",
       " 'description': 'sofrony LoRA adapter',\n",
       " 'created_at': 1744636074,\n",
       " 'status': 'validating'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_lora_from_url(name, url):\n",
    "    lora_creation_request = {\n",
    "        \"source\": url,\n",
    "        \"base_model\": \"meta-llama/Meta-Llama-3.1-8B-Instruct\",\n",
    "        \"name\": name,\n",
    "        \"description\": \"sofrony LoRA adapter\"\n",
    "    }\n",
    "    response = requests.post(f\"{api_url}/v0/models\", \n",
    "        json=lora_creation_request,\n",
    "        headers={\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {os.getenv('NB_STUDIO_API_KEY')}\"}) \n",
    "    return response.json()\n",
    "\n",
    "create_lora_from_url('sofrony-URL', 'huggingface.co/sofrony/Llama-3.1-8B-Instruct-sofrony')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How can I assist you today?'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(\"meta-llama/Meta-Llama-3.1-8B-Instruct-LoRa:sofrony-URL-cdRh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'meta-llama/Meta-Llama-3.1-8B-Instruct-LoRa:sofrony-URL-cdRh',\n",
       " 'base_model': 'meta-llama/Meta-Llama-3.1-8B-Instruct',\n",
       " 'source': 'sofrony/Llama-3.1-8B-Instruct-sofrony',\n",
       " 'description': 'sofrony LoRA adapter',\n",
       " 'created_at': 1744636074,\n",
       " 'status': 'deleted'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delete_lora('meta-llama/Meta-Llama-3.1-8B-Instruct-LoRa:sofrony-URL-cdRh').json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
